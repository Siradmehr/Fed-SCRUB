\documentclass[a4paper,12pt]{article}

% Package for better typography
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Package for inputting references
\usepackage[backend=biber,style=apa,citestyle=authoryear]{biblatex}
\addbibresource{ref.bib} % Reference file

% Packages for formatting
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% Package for mathematical equations
\usepackage{amsmath, amssymb}

% Package for figures
\usepackage{graphicx}

% Package for hyperlinks
\usepackage{hyperref}

% Title and author
\title{Fed-SCRUB: Extending SCRUB to Federated Learning}
\author{}
\date{\today}

\begin{document}

\maketitle

Let's begin by focusing the work of \cite{halimi2022federated}, which focuses on federated unlearning in a passive unlearning scenario, where the goal is to \textbf{remove all data} associated with a specific node. Their approach involves maximizing the loss function of that node instead of minimizing it.
In \cite{halimi2022federated}, each client \( i \) trains a local model with parameters \( \mathbf{w} \) by minimizing its empirical risk:

\[
\min_{\mathbf{w} \in \mathbb{R}^d} F_i(\mathbf{w}) := \frac{1}{n_i} \sum_{j \in \mathcal{D}_i} L(\mathbf{w}; (\mathbf{x}_j, y_j)),
\]

where \( L(\mathbf{w}; (\mathbf{x}_j, y_j)) \) is the prediction loss on sample \( (\mathbf{x}_j, y_j) \). The global federated learning (FL) model, denoted as \( \mathbf{w}^T \), is obtained after \( T \) communication rounds by aggregating local models from all clients.

During unlearning, the goal is to remove the influence of client \( i \) while keeping the model close to a reference model, \( \mathbf{w}_{\text{ref}} \), which represents the average of other clients' updates:

\[
\mathbf{w}_{\text{ref}} = \frac{1}{N-1} \sum_{j \neq i} \mathbf{w}_j^{T-1}.
\]

Client \( i \) can compute this reference locally as:

\[
\mathbf{w}_{\text{ref}} = \frac{1}{N-1} \left( N\mathbf{w}^T - \mathbf{w}_i^{T-1} \right),
\]

where \( \mathbf{w}_i^{T-1} \) is client \( i \)’s last local model before unlearning. To effectively remove its contribution, client \( i \) maximizes its empirical loss within an \( \ell_2 \)-norm ball of radius \( \delta \) around \( \mathbf{w}_{\text{ref}} \):

\[
\max_{\mathbf{w} \in \{\mathbf{v} \in \mathbb{R}^d : \|\mathbf{v} - \mathbf{w}_{\text{ref}}\|_2 \leq \delta\}} F_i(\mathbf{w}).
\]

This ensures the model forgets the target client’s data while maintaining alignment with the global model trained on the remaining clients.


However, as noted by \cite{georgiev2024attributetodeletemachineunlearningdatamodel}, this strategy is not optimal. The key limitation is that the exact loss function value for a model trained from scratch remains unknown, making the maximization approach less effective. Furthermore, considering that removing all data points is not always realistic.
\section{Idea}
Instead of maximizing the loss function for all data points, we can use SCRUB by defining the loss function as:
\[\frac{\alpha}{N_r} \sum_{x_r \in S_R} d_f(x_r; w^u) + \frac{\gamma}{N_r} \sum_{(x_r, y_r) \in S_R} \ell_f(h(x_r; w^u), \mathbf{Y}_r) - \frac{1}{N_f} \sum_{x_f \in S_F} d_f(x_f; w^u)\]

where \( d_f(x_r; w^u) \) represents a divergence measure, and \( \ell_f(h(x_r; w^u), \mathbf{Y}_r) \) denotes the loss function based on the model prediction.


Considering that different divergence measures exhibit varying levels of robustness, we adopt f-SCRUB, which leverages the flexibility of \( f \)-divergences to improve the stability and effectiveness of the unlearning process.


\section{Any theoretical Guarantee?}
It can be developed, because what are we doing is sum on functions optimization via $f$-divergence which had been explored before.


\printbibliography % Print the references
\end{document}