\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\citation{kurmanji2023unboundedmachineunlearning}
\citation{exampleRobustUnlearningPaper}
\citation{examplePrivacyUnlearningPaper}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1}Federated Machine Unlearning}{1}{subsection.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.1.1}Scenario I: Unlearning the \textit  {Effect} (Robustness-Oriented)}{2}{subsubsection.0.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Example.}{2}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Federated Update.}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Desirable Property: Improved Performance on Forget Set.}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Global Generalization Constraint.}{2}{section*.4}\protected@file@percent }
\citation{kurmanji2023unboundedmachineunlearning}
\citation{mantelero2013eu}
\citation{kurmanji2023unboundedmachineunlearning}
\@writefile{toc}{\contentsline {paragraph}{Remarks.}{3}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2}Federated Machine Unlearning}{3}{subsection.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3}$f$-SCRUB for Federated Unlearning}{3}{subsection.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Experiments and Results}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{3}{section.2}\protected@file@percent }
\citation{ginart2019makingaiforgetyou}
\citation{kurmanji2023unboundedmachineunlearning}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Divergences and their corresponding generator functions}}{4}{table.1}\protected@file@percent }
\newlabel{tab:divergences}{{1}{4}{Divergences and their corresponding generator functions}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Preliminaries}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Machine Unlearning}{4}{subsection.3.1}\protected@file@percent }
\citation{kurmanji2023unboundedmachineunlearning}
\citation{kurmanji2023unboundedmachineunlearning}
\citation{georgiev2024attributetodeletemachineunlearningdatamodel}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2} $f$-SCRUB}{5}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment and Results}{5}{section.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Forgetting scenarios.}}{6}{table.2}\protected@file@percent }
\newlabel{tab:forgetting_scenarios}{{2}{6}{Forgetting scenarios}{table.2}{}}
\citation{kurmanji2023unboundedmachineunlearning}
\citation{sekhari2021rememberwantforgetalgorithms}
\newlabel{fig:image1}{{1(a)}{7}{Subfigure 1(a)}{subfigure.1.1}{}}
\newlabel{sub@fig:image1}{{(a)}{7}{Subfigure 1(a)\relax }{subfigure.1.1}{}}
\newlabel{fig:image2}{{1(b)}{7}{Subfigure 1(b)}{subfigure.1.2}{}}
\newlabel{sub@fig:image2}{{(b)}{7}{Subfigure 1(b)\relax }{subfigure.1.2}{}}
\newlabel{fig:image3}{{1(c)}{7}{Subfigure 1(c)}{subfigure.1.3}{}}
\newlabel{sub@fig:image3}{{(c)}{7}{Subfigure 1(c)\relax }{subfigure.1.3}{}}
\newlabel{fig:image4}{{1(d)}{7}{Subfigure 1(d)}{subfigure.1.4}{}}
\newlabel{sub@fig:image4}{{(d)}{7}{Subfigure 1(d)\relax }{subfigure.1.4}{}}
\newlabel{fig:image5}{{1(e)}{7}{Subfigure 1(e)}{subfigure.1.5}{}}
\newlabel{sub@fig:image5}{{(e)}{7}{Subfigure 1(e)\relax }{subfigure.1.5}{}}
\newlabel{fig:image6}{{1(f)}{7}{Subfigure 1(f)}{subfigure.1.6}{}}
\newlabel{sub@fig:image6}{{(f)}{7}{Subfigure 1(f)\relax }{subfigure.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The \textit  {Max Loss} represents the loss of the forget set, which we aim to maximize, while the \textit  {Min Loss} corresponds to the retain set loss, which we seek to minimize. Notably, in the first phase, each epoch involves both a maximization and a minimization step. However, after transitioning to the next phase, we perform only minimization.}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {JS (6 classes)}}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {JS (5 classes)}}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {JS (2 classes)}}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {KL (6 classes)}}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {KL (5 classes)}}}{7}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {KL (2 classes)}}}{7}{figure.1}\protected@file@percent }
\newlabel{fig:combined_all}{{1}{7}{The \textit {Max Loss} represents the loss of the forget set, which we aim to maximize, while the \textit {Min Loss} corresponds to the retain set loss, which we seek to minimize. Notably, in the first phase, each epoch involves both a maximization and a minimization step. However, after transitioning to the next phase, we perform only minimization}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{7}{section.5}\protected@file@percent }
\newlabel{err}{{5}{7}{Discussion}{section.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Results for various forgetting scenarios with KL-KL being the baseline and KL-JS as main scenario, training for five intermittent maximization-minimization steps followed by five minimization step}}{8}{table.3}\protected@file@percent }
\newlabel{tab:forgetting_results_5}{{3}{8}{Results for various forgetting scenarios with KL-KL being the baseline and KL-JS as main scenario, training for five intermittent maximization-minimization steps followed by five minimization step}{table.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{8}{section.6}\protected@file@percent }
\bibdata{iclr2025_conference}
\bibstyle{iclr2025_conference}
\citation{cao2015towards}
\citation{nguyen2020variational}
\citation{thudi2022unrolling}
\citation{guo2019certified}
\citation{sekhari2021rememberwantforgetalgorithms}
\citation{li2024machine}
\citation{hayes2024}
\citation{hayes2024}
\citation{georgiev2024attributetodeletemachineunlearningdatamodel}
\citation{aminian2024robustsemisupervisedlearningfdivergence,roulet2025lossfunctionsoperatorsgenerated,novello2024fdivergencebasedclassificationuse,wang2023reverseklgeneralizingdirect}
\citation{bonato2025retain}
\citation{jeon2024information}
\citation{rangel2024learning}
\citation{wang2024llm}
\citation{goodfellow2014generativeadversarialnetworks}
\citation{nowozin2016fgantraininggenerativeneural}
\citation{reid2009informationdivergenceriskbinary}
\citation{duchi2020learningmodelsuniformperformance}
\@writefile{toc}{\contentsline {section}{\numberline {A}Related Works}{9}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Motivations for JS divergence and $\chi ^2$-divergence}{9}{appendix.B}\protected@file@percent }
\newlabel{appendix:A}{{B}{9}{Motivations for JS divergence and \texorpdfstring {$\chi ^2$}{chi-square}-divergence}{appendix.B}{}}
\citation{Nguyen_2010}
\@writefile{toc}{\contentsline {section}{\numberline {C}Scenarios Motivations}{10}{appendix.C}\protected@file@percent }
\newlabel{exp:Scenario}{{C}{10}{Scenarios Motivations}{appendix.C}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Simulation details}{10}{appendix.D}\protected@file@percent }
\newlabel{detail:epx}{{D}{10}{Simulation details}{appendix.D}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Overshoot/ Undershoot Discussion}{10}{appendix.E}\protected@file@percent }
\newlabel{appendix:Over/Under}{{E}{10}{Overshoot/ Undershoot Discussion}{appendix.E}{}}
\newlabel{fig:image3_A}{{E}{11}{Overshoot/ Undershoot Discussion}{appendix.E}{}}
\newlabel{fig:image3_B}{{E}{11}{Overshoot/ Undershoot Discussion}{appendix.E}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparing the effect of using a vanilla model (right) versus a maximum-capacity model (left) for KL-KL.}}{11}{figure.2}\protected@file@percent }
\newlabel{fig:Fig3}{{2}{11}{Comparing the effect of using a vanilla model (right) versus a maximum-capacity model (left) for KL-KL}{figure.2}{}}
\newlabel{fig:image4_A}{{E}{11}{Overshoot/ Undershoot Discussion}{figure.2}{}}
\newlabel{fig:image4_B}{{E}{11}{Overshoot/ Undershoot Discussion}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparing the effect of using a vanilla model(right) versus a maximum-capacity model (left) for KL-JS.}}{11}{figure.3}\protected@file@percent }
\newlabel{fig:Fig4}{{3}{11}{Comparing the effect of using a vanilla model(right) versus a maximum-capacity model (left) for KL-JS}{figure.3}{}}
\newlabel{fig:image5_A}{{E}{11}{Overshoot/ Undershoot Discussion}{figure.3}{}}
\newlabel{fig:image5_B}{{E}{11}{Overshoot/ Undershoot Discussion}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces This is the Extended scenario for KL-JS .}}{11}{figure.4}\protected@file@percent }
\newlabel{fig:Fig5}{{4}{11}{This is the Extended scenario for KL-JS }{figure.4}{}}
\newlabel{fig:image6_A}{{E}{12}{Overshoot/ Undershoot Discussion}{figure.4}{}}
\newlabel{fig:image6_B}{{E}{12}{Overshoot/ Undershoot Discussion}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces This is the Extended scenario for KL-KL}}{12}{figure.5}\protected@file@percent }
\newlabel{fig:Fig6}{{5}{12}{This is the Extended scenario for KL-KL}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Combination of Losses}{13}{appendix.F}\protected@file@percent }
\newlabel{appendix:All}{{F}{13}{Combination of Losses}{appendix.F}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results for various forgetting scenarios with combinations of KL $\times $ \{KL, JS, $\chi ^2$\}, training for five intermittent maximization-minimization steps followed by five minimization step}}{13}{table.4}\protected@file@percent }
\newlabel{tab:forgetting_results_5_KL}{{4}{13}{Results for various forgetting scenarios with combinations of KL $\times $ \{KL, JS, $\chi ^2$\}, training for five intermittent maximization-minimization steps followed by five minimization step}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results for various forgetting scenarios with combinations of X2 $\times $ \{KL, JS, $\chi ^2$\}, training for five intermittent maximization-minimization steps followed by five minimization step}}{14}{table.5}\protected@file@percent }
\newlabel{tab:forgetting_results_5_X2}{{5}{14}{Results for various forgetting scenarios with combinations of X2 $\times $ \{KL, JS, $\chi ^2$\}, training for five intermittent maximization-minimization steps followed by five minimization step}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Results for various forgetting scenarios with combinations of KL $\times $ \{KL, JS, $\chi ^2$\}, training for two intermittent maximization-minimization steps followed by one minimization step}}{15}{table.6}\protected@file@percent }
\newlabel{tab:forgetting_results_2_KL}{{6}{15}{Results for various forgetting scenarios with combinations of KL $\times $ \{KL, JS, $\chi ^2$\}, training for two intermittent maximization-minimization steps followed by one minimization step}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Results for various forgetting scenarios with combinations of X2 $\times $ \{KL, JS, $\chi ^2$\}, training for two intermittent maximization-minimization steps followed by one minimization step}}{16}{table.7}\protected@file@percent }
\newlabel{tab:forgetting_results_2_X2}{{7}{16}{Results for various forgetting scenarios with combinations of X2 $\times $ \{KL, JS, $\chi ^2$\}, training for two intermittent maximization-minimization steps followed by one minimization step}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Results for various forgetting scenarios with combinations of JS $\times $ \{KL, JS, $\chi ^2$\}, training for two intermittent maximization-minimization steps followed by one minimization step}}{17}{table.8}\protected@file@percent }
\newlabel{tab:forgetting_results_2_JS}{{8}{17}{Results for various forgetting scenarios with combinations of JS $\times $ \{KL, JS, $\chi ^2$\}, training for two intermittent maximization-minimization steps followed by one minimization step}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Results for various forgetting scenarios with combinations of JS $\times $ \{KL, JS, $\chi ^2$\}, training for five intermittent maximization-minimization steps followed by five minimization step}}{18}{table.9}\protected@file@percent }
\newlabel{tab:forgetting_results_5_JS}{{9}{18}{Results for various forgetting scenarios with combinations of JS $\times $ \{KL, JS, $\chi ^2$\}, training for five intermittent maximization-minimization steps followed by five minimization step}{table.9}{}}
\gdef \@abspage@last{18}
