
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
\usepackage{tcolorbox}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{float}
\usepackage{xspace}
\usepackage{subfigure}
\usepackage[colorinlistoftodos, color=blue!30!white %   ,shadow
	% ,disable
]{todonotes}                                        
\setlength{\marginparwidth}{2.5cm}
\newcommand{\todoa}[2][]{\todo[size=tiny,color=blue!20!white,#1]{GA: #2}\xspace}
\newcommand{\todor}[2][]{\todo[size=tiny,color=red!20!white,#1]{RK: #2}\xspace}
%-------------------------NEW PACKAGES
\input{new_packages}
%_______________________________________
\title{$f$-SCRUB: Unbounded Machine Unlearning Via $f$-divergences}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.
\author{ Radmehr Karimian \textsuperscript{\textdagger}, Amirhossien Bagheri \textsuperscript{\textdagger}, Gholamali Aminian \\
Department of Computer Science\\
Cranberry-Lemon University\\
Pittsburgh, PA 15213, USA \\
\texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
\And
Ji Q. Ren \& Yevgeny LeNet \\
Department of Computational Neuroscience \\
University of the Witwatersrand \\
Joburg, South Africa \\
\texttt{\{robot,net\}@wits.ac.za} \\
\AND
Coauthor \\
Affiliation \\
Address \\
\texttt{email}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors' names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\setlength{\marginparwidth}{2.5cm}
%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Deep Machine Unlearning addresses the problem of removing the effect of a subset of data points from a trained model. Machine Unlearning has various implications for the performance of algorithms. A well-known algorithm, SCRUB~\citep{kurmanji2023unboundedmachineunlearning}, has served as a baseline and achieved key objectives such as removing biases, resolving confusion caused by mislabeled data in trained models, and allowing users to exercise their "right to be forgotten" to protect user privacy. Building on this algorithm, we introduce $f$-SCRUB, an extension of SCRUB that employs different $f$-divergences instead of KL divergence. We analyze the role of these divergences and their impact on the resolution of unlearning problems in various scenarios.
\end{abstract}
\vspace{-0.25in}
\section{Introduction}

Rapid advancements in modern machine learning systems, coupled with their widespread adoption across various domains, have raised an important question: What happens if a user no longer wants their data to be utilized? This issue, along with the EU's 'right to be forgotten' \citep{mantelero2013eu}, presents the challenge of removing or 'unlearning' the impact of specific training examples from a trained model. Beyond user privacy, model safety is also a critical concern, particularly in mitigating the effects of toxic, outdated, or poisoned data. Addressing these challenges is essential for securing foundation models and ensuring the reliability and robustness of classical machine learning models, such as classifiers.
% \todoa{pls say what was the problem of scrub and how we can solve that via f-divergence?}
\newline One of the prominent approaches for machine unlearning, SCRUB \citep{kurmanji2023unboundedmachineunlearning}, introduces a teacher-student framework where the student selectively discards knowledge related to the data to be removed. The versatility of SCRUB allows it to avoid other methods' scalability and assumption constraints. However, it faces challenges in balancing the model's performance on retained data while achieving high error on removed data.

\textbf{Our Contribution}:
 In this work, we introduce \textbf{${f}$-SCRUB}, an extension of SCRUB that incorporates a novel framework based on $f$-divergences. In particular, our contributions are, \textit{(a)} using $f$-divergences in SCRUB framework, \textit{(b)} comprehensive experiments investigating different combinations of $f$-divergences in $f$-SCRUB.
\vspace{-0.1in}
\section{Preliminaries}
\vspace{-0.1in}
\textbf{$f$ -\textbf{divergence}:} The $f$ -divergences are information measures that generalize various divergences, such as Kullback-Leibler (KL) divergence, through the use of a convex generator function $f$. Given two discrete distributions $P = \{p_i\}_{i=1}^{k}$ and $Q = \{q_i\}_{i=1}^{k}$, the $f$-divergence between them is defined as:
\[
D_f(P \parallel Q) := \sum_{i=1}^{k} q_i f\left( \frac{p_i}{q_i} \right)
\]
where $f: (0, \infty) \to \mathbb{R}$ is a convex function with the property that $f(1) = 0$. This definition implies that $D_f(P \parallel Q) = 0$ if and only if $P = Q$. By choosing different forms for $f$, we obtain different types of divergences. For example, when $f(t) = t \log(t)$, we get the Kullback-Leibler (KL) divergence, which measures the difference between two probability distributions. In this work, we focus on JS-divergence and $\chi^2$-diveregence.

\begin{table*}[t]
    \centering
    \setlength{\tabcolsep}{10pt} % Adjust column spacing
    \renewcommand{\arraystretch}{1.3} % Increase row height
    \caption{Divergences and their corresponding generator functions}
    \label{tab:divergences}
    \resizebox{0.6\textwidth}{!}{\begin{tabular}{>{\centering\arraybackslash}m{4cm} >{\centering\arraybackslash}m{6cm}} 
        \toprule
        \textbf{Divergence} & \textbf{Generator Function} $f(t)$ \\ 
        \midrule
        KL-divergence & $t \log t$ \\ 
        $\chi^2$-divergence & $(1 - t)^2$ \\ 
        JS-divergence & $t \log \left( \frac{2t}{1+t} \right) + \log \left( \frac{2}{1+t} \right)$ \\ 
        \bottomrule
    \end{tabular}}
\end{table*}


\subsection{Machine Unlearning}
Consider a machine learning model $\theta \sim \mathcal{A}(S)$ trained on a dataset $S$. Given a "forget set" $S_F \subset S$ and a corresponding "retain set" $S_R = S \setminus S_F$, the goal of an \textit{exact unlearning} algorithm is to produce a sample from $\mathcal{A}(S_R)$ starting from the trained model $\theta$.
%\citep{ginart2019exact}

\begin{definition}[Exact unlearning \citep{ginart2019makingaiforgetyou}]
An unlearning algorithm $\mathcal{U}: \Theta \times 2^{|S|} \to \Theta$ is considered an exact unlearning algorithm if, for all $S_F \subset S$, $\mathcal{U}(\mathcal{A}(S), S_F) \overset{d}{=} \mathcal{A}(S_R)$, where $\overset{d}{=}$ denotes equality in distribution over models.
\end{definition}
\begin{definition}[Approximate unlearning]
An unlearning algorithm $\mathcal{U}: \Theta \times 2^{|S|} \to \Theta$ is said to perform approximate unlearning if, for all $S_F \subset S$, the output of $\mathcal{U}(\mathcal{A}(S), S_F)$ is close to $\mathcal{A}(S_R)$ in terms of some divergence measure $d(\cdot, \cdot)$, i.e.,

\[
d(\mathcal{U}(\mathcal{A}(S), S_F), \mathcal{A}(S_R)) \leq \epsilon,
\]

where $\epsilon$ is a small constant, indicating that the model after unlearning is approximately equivalent to a model retrained on the retain set $S_R$.
\end{definition}
\textbf{SCRUB:} The SCRUB method~\citep{kurmanji2023unboundedmachineunlearning} proposes a novel approach to unlearning as a Approximate unlearning method, where a student model is trained to selectively obey a teacher model. The goal is twofold: to forget the forget set $S_F$ while still retaining knowledge about the retain set $S_R$. The model $w^u$ (the student) is initialized with the teacher’s weights $w^o$, and the key idea is to optimize the student’s performance on the retain set while forgetting the forget set. The loss function used in SCRUB incorporates several components. It begins with the Kullback-Leibler (KL) divergence between the student and teacher output distributions for each example $x$, given by:

\[
d_{\mathrm{KL}}(x; w^u) = D_{KL}(h(x; w^u) || h(x; w^o)),
\]
where $h(x; w^u)$ is the output of Softmax layer.
This encourages the student model to stay close to the teacher for the retain set, ensuring it performs well on $S_R$. However, to encourage forgetting the forget set, the method adds a contrastive term to the objective, which forces the student to move away from the teacher on examples from the forget set $S_F$. The objective then becomes:
\[
\min_{w^u} \frac{1}{N_r} \sum_{x_r \in S_R} d_{\mathrm{KL}}(x_r; w^u) - \frac{1}{N_f} \sum_{x_f \in S_F} d_{\mathrm{KL}}(x_f; w^u)
\]
Furthermore, SCRUB simultaneously optimizes the task loss on the retain set to further enhance performance on the relevant examples, resulting in the final loss function:
\[
\min_{w^u} \frac{\alpha}{N_r} \sum_{x_r \in S_R} d_{\mathrm{KL}}(x_r; w^u) + \frac{\gamma}{N_r} \sum_{(x_r, y_r) \in S_R} \ell(h(x_r; w^u), \mathbf{Y}_r) - \frac{1}{N_f} \sum_{x_f \in S_F} d_{\mathrm{KL}}(x_f; w^u),
\]

where $\ell$ represents the cross-entropy loss, and $\alpha$ and $\gamma$ are hyperparameters controlling the importance of each term and $\mathbf{Y}_r$ is the hot-encode of labels vector for given feature $x_r$. This formulation allows SCRUB to balance the tradeoff between retaining performance on the retain set and forgetting data from the forget set, addressing the core challenge of machine unlearning.

\subsection{ \texorpdfstring{$f$}{f}-SCRUB}

Here we introduce \texorpdfstring{$f$}{f}-SCRUB, a novel approach for unlearning in machine learning models. We separate the losses based on \citep{kurmanji2023unboundedmachineunlearning} into two distinct components. 
\newline \textbf{Maximization Loss:} This loss is defined as 
\[\frac{1}{N_f} \sum_{x_f \in S_F} d_f(x_f; w^u),\] where aims to maximize the divergence between the unlearned model and the data points that need to be forgotten. 
\newline \textbf{Minimization Loss:} This loss is defined as 
\[\frac{\alpha}{N_r} \sum_{x_r \in S_R} d_f(x_r; w^u) + \frac{\gamma}{N_r} \sum_{(x_r, y_r) \in S_R} \ell_f(h(x_r; w^u), \mathbf{Y}_r),\] where $\ell_f(\cdot,\cdot)$ is the loss function inspired via $f$-divergence. We aim to minimize the divergence between the unlearned model and the remaining data points, while also ensuring that the model's predictions remain accurate. 
\newline We choose different \texorpdfstring{$f$}{f}-divergences for each component in different scenarios.
We modify our loss functions and introduce \textit{f-SCRUB} by selecting different $f$-divergences for minimization and maximization losses.  While \textit{$f$-SCRUB} allows the flexibility to explore various $f$-divergences as loss functions, in this work, we limit our choices to three divergences. In particular, the divergence terms $d_f(x_r; w^u)$ and $d_f(x_f; w^u)$ are chosen from the Kullback-Leibler (KL), Jensen-Shannon (JS), and $\chi^2$ divergences. The rationale behind this selection is provided in Appendix \ref{appendix:A}.
\vspace{-0.1in}
\section{Experiment and Results}
\vspace{-0.1in}
For our simulations, we use the same framework as \citep{kurmanji2023unboundedmachineunlearning}. We conducted our experiments on the CIFAR-10 dataset and selected ResNet-18 as our model. You can find our code at  \href{https://anonymous.4open.science/r/F-Scrube-8DEC/README.md}{Ananymous github}. You can find the details of our simulations in Appendix \ref{detail:epx}.

\textbf{Scenarios:} In the literature, two common forgetting scenarios have been discussed: forgetting an entire class (Class 5) and forgetting a subset of 100 examples from Class 5. To extend these investigations, we introduce more challenging scenarios, summarized in Table \ref{tab:forgetting_scenarios}. We provide the motivations for choosing these scenarios in Appendix~\ref{exp:Scenario}.

\begin{table*}[t]
    \centering
        \caption{Forgetting scenarios.}
    \label{tab:forgetting_scenarios}

    \resizebox{0.6\textwidth}{!}{\begin{tabular}{ccc}
        \toprule
        \textbf{Scenario Name} & \textbf{Classes} & \textbf{Number to Forget} \\
        \midrule
        Complete (1) & Entire class 5 & All \\
        \cmidrule{2-3}
        Light (2) & Class 5 & 100 \\
        \cmidrule{2-3}
        Moderate (3) & Class 5 & 500 \\
        \cmidrule{2-3}
        Dual Light (4) & Classes 4, 5 & 100 each \\
        \cmidrule{2-3}
        Dual (5) & Classes 4, 5 & 500 each \\
        \cmidrule{2-3}
        Broad Light (6) & Classes 1, 2, 3, 4, 5 & 100 each \\
        \cmidrule{2-3}
        Broad (7) & Classes 1, 2, 3, 4, 5 & 500 each \\
        \cmidrule{2-3}
        Extended Light (8) & Classes 1, 2, 3, 4, 5, 6 & 100 each \\
        \cmidrule{2-3}
        Extended (9) & Classes 1, 2, 3, 4, 5, 6 & 500 each \\
        \bottomrule
    \end{tabular}}
    \vspace{-0.2in}
\end{table*}
% \vspace{-1in}
\textbf{Overshoot / Undershoot:} As noted in \cite{georgiev2024attributetodeletemachineunlearningdatamodel}, one of the challenges SCRUB faces is the uncertainty in the loss function values for forget set members. Since these values are unknown, simply increasing their loss may not be an optimal solution. Depending on the number of training epochs, SCRUB can lead to overshooting or undershooting the intended loss adjustment. Therefore, we aim to explore whether using a more robust loss function, such as JS or $\chi^2$ divergence, can yield a loss function that is inherently more stable and reliable in unlearning scenarios.
Since KL divergence has become the standard loss function for the retain set, we focus on using JS and $\chi^2$ divergences as the loss functions for the forget set. A detailed analysis of other loss functions is provided in the appendix.

In simpler scenarios, such as unlearning 100 data points from a single class, using KL divergence as the loss function for the forget set does not exhibit significant variance. However, in more challenging unlearning scenarios, such as unlearning 500 data points across six classes, the variance of the forget set loss increases significantly. In contrast, JS divergence remains more stable, demonstrating lower variance even in complex unlearning settings.

In Figure \ref{fig:combined_all}, we present the loss values where JS divergence is applied to the forget set and KL divergence to the retain set. These results correspond to the Exceptionally Challenging, Highly Difficult, and Difficult scenarios.

In contrast, the right figure shows a case where KL divergence is applied to both sets. As observed, the forget set exhibits higher variance and greater data dependence when using KL compared to JS.

As shown in Figures \ref{fig:image1} and \ref{fig:image4}, KL divergence is highly dependent on the data and exhibits significant variance. A similar trend is observed in Figures \ref{fig:image2} and \ref{fig:image5}. However, when unlearning a smaller number of data points, neither JS nor KL shows substantial variance in their loss values. This suggests that in simpler unlearning scenarios, where the process is less sensitive to data variations, both divergences behave similarly, as seen in Figures \ref{fig:image3} and \ref{fig:image6}.

\begin{figure}[H]
    \centering
    \vspace{-10pt}
    \subfigure[JS (6 classes)]{
        \includegraphics[width=0.24\linewidth]{Images/KL_JS_500_6.png}
        \label{fig:image1}
    }
    \hfill
    \subfigure[JS (5 classes)]{
        \includegraphics[width=0.24\linewidth]{Images/KL_JS_500_5.png}
        \label{fig:image2}
    }
    \hfill
    \subfigure[JS (2 classes)]{
        \includegraphics[width=0.24\linewidth]{Images/KL_JS_500_2.png}
        \label{fig:image3}
    }
    \hfill
    \subfigure[KL (6 classes)]{
        \includegraphics[width=0.24\linewidth]{Images/KL_KL_500_6.png}
        \label{fig:image4}
    }
    \hfill
    \subfigure[KL (5 classes)]{
        \includegraphics[width=0.24\linewidth]{Images/KL_KL_500_5.png}
        \label{fig:image5}
    }
    \hfill
    \subfigure[KL (2 classes)]{
        \includegraphics[width=0.24\linewidth]{Images/KL_KL_500_2.png}
        \label{fig:image6}
    }
    \caption{The \textit{Max Loss} represents the loss of the forget set, which we aim to maximize, while the \textit{Min Loss} corresponds to the retain set loss, which we seek to minimize. Notably, in the first phase, each epoch involves both a maximization and a minimization step. However, after transitioning to the next phase, we perform only minimization.}
    \vspace{-10pt}
    \label{fig:combined_all}
\end{figure}
\vspace{-0.1in}
\section{Discussion} \label{err}
\vspace{-0.1in}
We analyze the performance of the models across different scenarios. In this section, we focus on KL-JS scenario, where we replace the KL-divergence maximization loss in SCRUB with JS-divergence, while additional cases are presented in the Appendix~\ref{appendix:All}. The best performance is achieved when the error in the forget set is maximized while the error in the test dataset is minimized. As shown in Table \ref{tab:forgetting_results_5}, using JS loss as the maximization loss generally results in \textbf{lower variance} across almost most of all scenarios.
c

To interpret these results, we define the best loss function as the one where the forgotten error is highest and the test error is lowest—both occurring in the same row. However, this is not always the case. With a more nuanced analysis, we argue that KL-JS performs better in most scenarios with confidence. In cases where it does not, model degradation complicates the analysis and introduces significant complexity. Additionally, when one approach excels in forget set error while the other performs better on test error, direct comparison becomes infeasible, preventing a definitive judgment.

In the complete forgetting scenario, where the goal is to forget all data from a specific class, the error on the forget set rapidly reaches 100\%. This phenomenon is also evident in Table \ref{tab:forgetting_results_2_KL} and other tables in the appendix. After two max-min epochs, minimizing with the largest possible batch size yields strong results, as demonstrated in \cite{kurmanji2023unboundedmachineunlearning}. The key point here is that because the entire class is absent, post-minimization does not affect the forget error as presented in Table \ref{tab:forgetting_results_5}.

As shown in Table \ref{tab:forgetting_results_5}, in the Light scenario, KL-JS outperforms the baseline. The only exception is in the full-capacity forget error, where KL-JS exhibits a marginally lower performance (0.34\%); however, this is negligible given that the baseline has twice the variance. The same pattern holds for the Light-Dual case, where KL-JS has a 0.16\% difference in the full-capacity scenario but nearly four times lower variance. In the Moderate case, KL-JS clearly outperforms the baseline in the Vanilla setup, but in the full-capacity scenario, direct comparison is not feasible. In the full capacity case for Light-Broad, the KL$-$JS outperforming baseline is determined, and for Light-Extended comparison is not feasible.

Our observations indicate that in the Vanilla case for Moderate (forgetting 500 samples) and Dual up to Extended cases, the degradation in model performance is so severe that one could argue the model has effectively lost its knowledge. This highlights a critical limitation of Scrub—widely regarded as the best unlearning framework based on current literature—when the number of deleted samples per class increases. This issue presents emerging challenges in the field, which are highly relevant to real-world scenarios. A similar problem is also addressed in \citep{sekhari2021rememberwantforgetalgorithms}. Broad and Extended cases in full capacity also suffer the same problem mentioned here. As you can see, there is not a single case where KL$-$KL outperforms KL$-$JS with full confidence and not degraded model.
\vspace{-0.1in}
\section{Conclusion}
\vspace{-0.1in}
As final conclusion, we introduced f-SCRUB, an extension of SCRUB that incorporates f-divergences to improve the stability and effectiveness of machine unlearning. By leveraging JS and $\chi^2$ divergences, our approach addresses the overshoot/undershoot problem inherent in existing methods, leading to more reliable and controlled unlearning. Our extensive experiments demonstrate that different divergence choices significantly impact forgetting accuracy, retention performance, and model stability. Notably, JS divergence offers a more stable unlearning process. These findings suggest that carefully selecting divergence metrics can substantially improve the trade-off between forgetting and preserving essential model knowledge. Future work could explore robustness evaluation and privacy implications of these divergences, particularly their effectiveness against membership inference attacks (MIA).


\input{Files/forgetting_results_5}
\clearpage


\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\appendix
\newpage
\section{Related Works}

 Two primary frameworks have emerged to address the challenge of unlearning: exact unlearning \citep{cao2015towards} and approximate unlearning \citep{nguyen2020variational}. Exact unlearning requires retraining the model from scratch using only the remaining data, but this approach is computationally expensive and impractical for large-scale models \citep{thudi2022unrolling}. In contrast, approximate unlearning modifies the trained model to mimic the outcome of retraining on the remaining dataset. The key challenge in approximate unlearning is to ensure that the modified model is indistinguishable from a retrained one, often necessitating theoretical guarantees on the quality of the approximation \citep{guo2019certified}.

Although much of the unlearning research has focused on convex models \citep{sekhari2021rememberwantforgetalgorithms}, the non-convexity of deep neural networks complicates the process. As a result, effective unlearning remains a challenge, with heuristics often producing varying results across different benchmarks, making it difficult to ensure consistent reliability \citep{li2024machine}.

\citep{hayes2024} highlight a significant challenge in fine-tuning-based unlearning methods, known as the \textit{missing targets} problem. When unlearning a data point $x \in \textit{forget set}$, these methods typically apply gradient ascent on $x$ and gradient descent on the retain set to preserve model performance. However, gradient ascent can cause the loss on $x$ to grow indefinitely if unchecked. The desired outcome is to stop when the model's loss on $x$ matches the counterfactual loss (i.e., the loss of a model trained only on the retain set). This presents two main issues: (a) the target loss is unknown, and (b) the optimal stopping point may vary for different points in the forget set. As a result, unlearning algorithms often "undershoot" or "overshoot" the target loss \citep{hayes2024}.

This problem is further analyzed in the work of \citep{georgiev2024attributetodeletemachineunlearningdatamodel}, which uses data modeling to address these challenges. Our research seeks to extend SCRUB to overcome this issue by introducing a loss function that is naturally robust to overshooting and undershooting by employing various $f$-divergences.

While $f$-divergences have been effective loss functions in various machine learning tasks ~\citep{aminian2024robustsemisupervisedlearningfdivergence,roulet2025lossfunctionsoperatorsgenerated,novello2024fdivergencebasedclassificationuse,wang2023reverseklgeneralizingdirect}, they have been primarily used for validating machine unlearning processes. For example, Jensen-Shannon (JS) divergence has been applied in the context of unlearning to validate the removal of data from models \citep{bonato2025retain}, \citep{jeon2024information}, \citep{rangel2024learning}. Furthermore, there has been some exploration of using $f$-divergences specifically for unlearning large language models (LLMs) \citep{wang2024llm}.
\section{Motivations for JS divergence and \texorpdfstring{$\chi^2$}{chi-square}-divergence}
\label{appendix:A}
In this section, we study some motivations behind choosing JS divergence and $\chi^2$ divergence. These information measures offer several advantages over KL divergence, particularly in applications involving generative modeling and robust regularization.

JS divergence is widely used as a loss function in Generative Adversarial Networks (GANs) due to its symmetric and bounded nature, which provides a stable measure of similarity between distributions (\cite{goodfellow2014generativeadversarialnetworks}). Unlike KL divergence, which can diverge to infinity when the two distributions have disjoint supports, JS divergence remains finite and well-behaved, making it particularly effective for comparing empirical distributions (\cite{nowozin2016fgantraininggenerativeneural}). This property is especially beneficial in our context, as it helps mitigate overshoot and undershoot problems, particularly in scenarios where exact loss values for removed data points are unavailable.

On the other hand, $\chi^2$ divergence emphasizes large discrepancies due to its squared difference term, making it particularly useful in outlier detection and robust learning frameworks (\cite{reid2009informationdivergenceriskbinary}). Regularizing with $\chi^2$ divergence can also help prevent models from becoming overly biased toward majority classes by strongly penalizing large probability gaps (\cite{duchi2020learningmodelsuniformperformance}). This property makes it particularly effective in imbalanced learning scenarios, where standard loss functions may fail to capture significant disparities between class distributions.

Thus, by leveraging JS divergence for stable probability comparisons and $\chi^2$ divergence for strong regularization and outlier sensitivity, we can achieve a more robust and balanced learning framework compared to using KL divergence alone.

Building on this, we modify our loss functions and introduce $f$-SCRUB, where we select different $f$-divergences for the retain set and the forget set. Each divergence term, $d(x_r; w^u)$ and $d(x_f; w^u)$, can be chosen from JS, KL, or $\chi^2$ divergences (\cite{Nguyen_2010}).

\section{Scenarios Motivations}\label{exp:Scenario}
The motivation behind these scenarios is twofold. First, as the number of forgotten samples increases, the impact on model performance in the retained set becomes more pronounced. Second, as more classes are involved, the complexity of the forgetting process increases, making the problem progressively more difficult.

An additional challenge arises in the evaluation phase: it becomes difficult to determine whether degraded performance on the forgetting set is due to successful forgetting or simply because the model is encountering previously unseen data. This ambiguity poses a fundamental challenge in measuring the effectiveness of forgetting strategies.

\section{Simulation details} \label{detail:epx}
We consider two versions of the model. The first, which we call the vanilla model, was trained on CIFAR-100 for 30 epochs and then fine-tuned on CIFAR-10 for another 30 epochs, achieving an accuracy of 0.84. We refer to this as the vanilla original model. Notably, this model does not operate at full capacity.
Since we believe that the unlearning frameworks should be independent of the original model’s training procedure, we also evaluate a full-capacity original model, which is a Torchvision pre-trained model with a precision of 0.96.

For the unlearning process, we apply two different policies. In the first, we perform two epochs of maximization, each followed by a minimization step, with an additional minimization step at the end. In the second, we extend the process to five maximization steps, each followed by a minimization step, concluding with five final minimization steps.
Our simulations run on a single NVIDIA RTX 4090 GPU. We use the PyTorch library for our experiments. To ensure simplicity and fair comparisons, we fix the retraining batch size at 64 and the forgetting batch size at 32. The remaining parameters are the same as those used in SCRUB.
\section{Overshoot/ Undershoot Discussion} \label{appendix:Over/Under}

Another key aspect we aim to highlight is the impact of transitioning from a vanilla model to a maximum-capacity model on the absolute values of loss functions. In the vanilla model, uncertainty arises from the model's inherent lack of confidence, introducing variance in the loss function values. However, in more challenging unlearning scenarios, this uncertainty can significantly influence the loss function. Even in simpler cases, such as removing 100 data points from six classes, changing the model does not affect the variance of the loss function but does alter its bias. While KL divergence is highly sensitive to individual data points (see figure \ref{fig:Fig3}), a similar effect can also be observed with JS divergence (see figure \ref{fig:Fig4}).
\begin{figure}[H]
    \centering
     \vspace{-8pt}
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_KL_max_100_6.png}
        \label{fig:image3_A}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_KL_Vanilla_100_6.png}
        \label{fig:image3_B}
    \end{minipage}
    \caption{Comparing the effect of using a vanilla model (right) versus a maximum-capacity model (left) for KL-KL.}
    \label{fig:Fig3}
\end{figure}
\begin{figure}[H]
    \centering
     \vspace{-16pt}
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_JS_max_100_6.png}
        \label{fig:image4_A}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_JS_Vanilla_100_6.png}
        \label{fig:image4_B}
    \end{minipage}
    \caption{Comparing the effect of using a vanilla model(right) versus a maximum-capacity model (left) for KL-JS.}
    \label{fig:Fig4}
\end{figure}
Additionally, we examine the impact of the number of training epochs on the loss function values at each step. In more complex and challenging scenarios, KL divergence demonstrates high sensitivity to individual data points, resulting in significant fluctuations when the algorithm is run for different numbers of epochs. In contrast, JS divergence, due to its bounded nature, offers greater stability and is less affected by such variations. As expected, increasing the number of training epochs shows that the loss values remain more consistent and robust when using the JS loss function (see figure \ref{fig:Fig5}), whereas KL divergence exhibits greater variability (see figure \ref{fig:Fig6}).
\begin{figure}[htp]
    \centering
     \vspace{-12pt}
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_JS_2_5_500_6.png}
        \label{fig:image5_A}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_JS_5_10_500_6.png}
        \label{fig:image5_B}
    \end{minipage}
    \caption{This is the Extended scenario for KL-JS .}
    \label{fig:Fig5}
\end{figure}
\begin{figure}[htp]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_KL_2_5.png}
        \label{fig:image6_A}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Images/KL_KL_5_!0.png}
        \label{fig:image6_B}
    \end{minipage}
    \caption{This is the Extended scenario for KL-KL}
    \label{fig:Fig6}
\end{figure}
\clearpage
\section{Combination of Losses} \label{appendix:All}
You can observe all nine combinations of maximization-minimization losses. As seen in the results, despite JS performing well as a maximization loss (as mentioned in Section~\ref{err}), it fails to recover the model when used as a minimization loss, as shown in Tab. \ref{tab:forgetting_results_2_JS} and Tab. \ref{tab:forgetting_results_5_JS}. This failure is due to the slow convergence of JS in minimization, making it unsuitable for this role.

Additionally, $\chi^2$ achieves the fastest recovery among all losses when used as a minimization loss, particularly in the Complete scenario, where the entire class is forgotten.

%\input{Files/forgetting_results_2}
\input{Files/forgetting_results_5_KL}
\input{Files/forgetting_results_5_X2}
\input{Files/forgetting_results_2_KL}
\input{Files/forgetting_results_2_X2}
\input{Files/forgetting_results_2_JS}
\input{Files/forgetting_results_5_JS}

% \section{Future Works}
% While f-SCRUB enhances unlearning performance, several open challenges remain, such as the effect of model capacity on unlearning efficiency, alongside developing adaptive divergence selection mechanisms that dynamically adjust to dataset characteristics, including imbalanced datasets. Understanding how different model sizes influence the stability and effectiveness of unlearning is crucial for extending our approach to larger architectures and real-world deployments. Additionally, while our work primarily focuses on reducing bias in the unlearning process, there are other critical aspects to consider, such as privacy guarantees and security risks.

% Future work should explore differential privacy mechanisms to ensure that unlearning not only removes specific data points but also prevents adversarial reconstruction attacks. Similarly, membership inference attacks, where an adversary attempts to determine whether a particular sample was part of the training set, remain a significant concern. Investigating how f-divergences impact these privacy vulnerabilities and integrating privacy-preserving techniques into f-SCRUB will be essential for making unlearning more secure, scalable, and widely applicable. Addressing these challenges will contribute to the broader goal of building trustworthy and privacy-aware AI systems.
\end{document}
